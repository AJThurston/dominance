---
title: "Dominance"
output: github_document
---

Visualization to demonstrate the relative importance of predictors from
a regression model using general dominance weights.\
[\@AJThurston](https://twitter.com/AJThurston)

```{r setup, warning = FALSE, message = FALSE}
library(summarytools)
library(tidyverse)
library(ggplot2)
library(lm.beta)
library(scales)
library(Cairo)
library(domir)
```

## Introduction

In academic contexts, explanation of a regression models typically focus
on the variance accounted for by the model and the beta weights
associated with each predictor. However, interpretation of beta weights
is difficult for lay audiences, and multicolinearity (i.e., highly
correlated predictors) can lead to misleading results (e.g., bouncing
betas). Further, non-technical audiences tend to give comparably less
weight to the relationships between predictors and criteria. Instead,
they tend to give more weight the rank order of the most important
predictors in order to prioritize direct attention or resources.

Relative importance analyses are tools for variance decomposition. They
address multicolinearity of predictors, offer non-technical audiences
with a ranking of the most important predictors and their relative
contribution to variance explained, and offer an intuitive visual aid
for describing incremental validity. There are two main relative
importance analyses: relative weights analysis (Johnson, 2000; Johnson &
Lebreton, 2004; Tonidandel & LeBreton, 2011) and dominance analysis
(Budescu, 1993; Azen & Traxel, 2009; Luchmann, 2014). In general,
relative weights analysis used to be preferred as it was less
computationally intensive; however, dominance analysis is preferred as
it is mathematically accurate, and should especially be preferred in
high-stakes testing settings or when statistically significant
differences between the relative contribution of predictors is the focus
of the test.

## Data Import

In this example, these simulated data have a correlation of r = .5
between predicted and actual criterion scores (N = 1000, M = 50, SD =
10). First, let's import the example data and quickly orient ourselves
to it. There are three variables in the file:

1.  id: This is just an identifier or a unique participant ID (integer)
2.  sex: Participant sex (character)
3.  eth: Participant ethnicity (character)
4.  race: Participant race (character)
5.  age: Participant age in years (integer)
6.  tenure: Participant tenure in months (numeric)
7.  gma: Participant cognitive ability/general mental ability score
    (integer)
8.  o: Participant personality, openness scale total score (integer)
9.  c: Participant personality, conscientiousness scale total score
    (integer)
10. e: Participant personality, extraversion scale total score (integer)
11. a: Participant personality, agreeableness scale total score
    (integer)
12. n: Participant personality, emotional Stability scale total score
    (integer)
13. sa: Participant situation awareness test total score (integer)
14. sp: Participant safety performance total score (integer)

Note: all items are self-reported, but cognitive ability was measured
with an ability test. Variables 2 through 13 are predictors, safety
performance (sp) is the criterion.

```{r data, message = FALSE, warning = FALSE}
# df <- read.csv("https://raw.githubusercontent.com/AJThurston/dominance/master/data/dominance.csv")
df <- read.csv("dominance.csv")
head(df)
```

## Regression Analysis (Baseline)

There are plenty of tools to conduct a linear regression in R. In this
example, we're demonstrating incremental validity with two blocks
demonstrating the incremental validity of situation awareness over
demographic, cognitive, and personality predicting safety performance.

```{r regression, eval = FALSE, message = FALSE, warning = FALSE}
mod1 <- lm(data = df, 
           formula = sp ~ sex + eth + race + age + tenure + gma + o + c + e + a + n)

mod2 <- lm(data = df,
           formula = sp ~ sex + eth + race + age + tenure + gma + o + c + e + a + n + sa)

mod1 %>%
  lm.beta(.) %>%
  summary(.)

mod2 %>%
  lm.beta(.) %>%
  summary(.)
```

![](https://raw.githubusercontent.com/AJThurston/dominance/master/img/regression_table.PNG)

## Dominance Analysis

Brief description of dominance analysis here

Need to give them fair warning about the 2\^p-1 thing

```{r da, eval = FALSE, message = FALSE, warning = FALSE}
dom1 <- domin(data = df,
              formula = sp ~ sex + eth + race + age + tenure + gma + o + c + e + a + n, 
              reg = lm, 
              fitstat = list(summary, "r.squared"))

dom2 <- domin(data = df,
              formula = sp ~ sex + eth + race + age + tenure + gma + o + c + e + a + n + sa, 
              reg = lm, 
              fitstat = list(summary, "r.squared"))
```

Now would be the time to migrate these values into a PowerPoint if you're doing a one-off.

```{r results, eval = FALSE, message = FALSE, warning = FALSE}
res <- list(dom1$General_Dominance,dom2$General_Dominance) %>%
  do.call(bind_rows, .) %>%
  as.data.frame() %>%
  mutate(tenure = 0) %>%
  mutate(personality = rowSums(.[c("o","c","e","a","n")])) %>%
  mutate(demographic = rowSums(.[c("sex","eth","race","age","tenure")])) %>%
  mutate(block = row_number()) %>%
  gather(var, val, -block)

res$var

res$total <- res$var %>%
  recode_factor(.,
                "sex"    = "part",
                "eth"    = "part",  
                "race"   = "part",  
                "age"    = "part",   
                "tenure" = "part",
                "gma"    = "unchanged",
                "o"      = "part",
                "c"      = "part", 
                "e"      = "part",
                "a"      = "part",
                "n"      = "part",
                "sa"     = "unchanged",
                "personality" = "total",
                "demographic" = "total")

res$var <- res$var %>%
  factor(., levels = c("sa", "personality", "gma", "demographic"))

```

Description of the data analysis here and perhaps a bit on tidy format data

## Dominance Plot

Dominance plot notes and explanation here
```{r domplot, message = FALSE, warning = FALSE}
p <- ggplot(data = res)
# p <- p + scale_y_continuous(name=y.title, limits = c(y.ll,y.ul), oob = rescale_none)
# p <- p + scale_x_continuous(name=x.title, oob = rescale_none)
p <- p + geom_bar(aes(x = val, y = as.factor(block), fill = var), 
                  stat = "identity", 
                  width = .5)
p
# p <- p + geom_text(aes(x = quant, y = actu, label = paste0(round(..y..,0),"%")), 
#                    stat = "summary", 
#                    fun = "mean",
#                    vjust = -1)
# p <- p + theme(text = element_text(size = txt.siz),
#                panel.background = element_rect(fill = "white", color = "black"),
#                panel.grid = element_blank(),
#                axis.text.y = element_text(color = 'black'),
#                axis.text.x = element_text(color = 'black'))
# p
```

## Export

These are some options for exporting your expectancy chart and the data
for use in other software programs.

```{r export, message=FALSE, warning=FALSE}
ggsave("expectancy.png", 
       plot = p, 
       scale = 1, 
       width = 6.5, 
       height = 4, 
       units = "in",
       dpi = 300,
       type = "cairo-png")

write.csv(data, "expectancy_appended.csv")
```

Limitations of Dominance Analysis

> First, DA cannot account for sampling and measurement errors, as is
> true of other analyses (Braun et al., 2019; Tonidandel & LeBreton,
> 2011). Second, although DA was invented to deal with correlations
> among PVs, it cannot rectify multicollinearity when multicollinearity
> is caused by two or more variables measuring the same construct (i.e.,
> construct redundancy; Stadler et al., 2017). Third, DA is not a
> replacement for multiple regression analysis for selecting the best
> set of PVs for the regression formula. That is, DA is an indispensable
> supplement to multiple regression analysis for determining predictor
> importance, but not the other way around. (Mizumoto, 2022)

## References

Azen, R., & Traxel, N. (2009). Using Dominance Analysis to Determine
Predictor Importance in Logistic Regression. Journal of Educational and
Behavioral Statistics, 34(3), 319--347.
<https://doi.org/10.3102/1076998609332754>

Budescu, D. V. (1993). Dominance analysis: A new approach to the problem
of relative importance of predictors in multiple regression.
Psychological Bulletin, 114, 542-551.

Johnson, J. W. (2000). A heuristic method for estimating the relative
weight of predictor variables in multiple regression. Multivariate
Behavioral Research, 35(1), 1-19. <doi:10.1207/S15327906MBR3501_1>

Johnson, J. W., & LeBreton, J. M. (2004). History and use of relative
importance indices in organizational research. Organizational Research
Methods, 7(3), 238-257. <doi:10.1177/1094428104266510>

Luchman, J. N. (2014). Relative Importance Analysis With Multicategory
Dependent Variables: An Extension and Review of Best Practices.
Organizational Research Methods, 17(4), 452-471.
<https://doi.org/10.1177/1094428114544509>

Mizumoto, A. (2023). Calculating the relative importance of multiple
regression predictor variables using
dominance analysis and random forests. *Language Learning*, *73*(1),
161-196.

Tonidandel, S., & LeBreton, J. M. (2011). Relative importance analysis:
A useful supplement to regression analysis. Journal of Business and
Psychology, 26(1), 1-9. <doi:10.1007/s10869-010-9204-3>

data = read.xlsx("data.relimpo.xlsx", sheetName = "Sheet1")

names = c("Y1","X1","X2","X3","X4","X5") nvars = length(names) preds =
c("X1","X2","X3","X4","X5") model1 = c("Y1 \~ X1 + X2 + X3") model2 =
c("Y1 \~ X1 + X2 + X3 + X4") model3 = c("Y1 \~ X1 + X2 + X3 + X4 + X5")
models = c(model1, model2, model3) colnames(data)

lm1 = lm(model1, data = data) lm_dominance1 \<- calc.relimp(lm1, type =
"lmg") lm1dom = lm_dominance1\$lmg lm1domcs = cumsum(lm1dom) lm1domm =
c(1,1,1,1,1)

lm2 = lm(model2, data = data) lm_dominance2 \<- calc.relimp(lm2, type =
"lmg") lm2dom = lm_dominance2\$lmg lm2domcs = cumsum(lm2dom) lm2domm =
c(2,2,2,2,2)

lm3 = lm(model3, data = data) lm_dominance3 \<- calc.relimp(lm3, type =
"lmg") lm3dom = lm_dominance3\$lmg lm3domcs = cumsum(lm3dom) lm3domm =
c(3,3,3,3,3)

n \<- max(length(lm1dom), length(lm2dom), length(lm3dom)) length(lm1dom)
\<- n\
length(lm2dom) \<- n length(lm3dom) \<- n length(lm1domcs) \<- n\
length(lm2domcs) \<- n length(lm3domcs) \<- n

domres1 = cbind(lm1domm,preds,lm1dom,lm1domcs) domres2 =
cbind(lm2domm,preds,lm2dom,lm2domcs) domres3 =
cbind(lm3domm,preds,lm3dom,lm3domcs) domres =
rbind(domres1,domres2,domres3) rownames(domres) = NULL colnames(domres)
= c("Model","Predictor","Importance","Cumul") domres =
as.data.frame(domres) domres$Importance = as.numeric(domres$Importance)
domres$Cumul = as.numeric(domres$Cumul)

rm(counts,p,preds,n,lm1,lm2,lm3,lm1dom,lm2dom,lm3dom,lm_dominance1,lm_dominance2,lm_dominance3)

imp.plot = ggplot(data = domres, aes(x = Model, y = Importance, fill =
Predictor) ) + geom_bar(stat="identity", position =
position_stack(reverse = TRUE), width = .25, color = "black" ) +
geom_text(data=domres,aes(x=Model,y=Cumul,label=paste0(Predictor, "\n",
round(Importance, digits = 2))),vjust=0) + scale_x\_discrete(limits =
rev(levels(domres\$Model))) + scale_y\_continuous(limits = c(0,50),
labels = scales::percent) + scale_fill_manual(values = USFcols) +
coord_flip() +

theme(text = element_text(size = 20), panel.background =
element_rect(fill = "white", color = "black"), panel.grid =
element_blank(), axis.text.y = element_text(color = 'black'),
axis.text.x = element_text(color = 'black'), axis.title.y =
element_blank(), panel.grid.major.x = element_line(color="black"),
legend.position = "top" ) imp.plot

# Write plot and data to working directory -----------------------

ggsave("relimpo.png", plot = plot1, scale = 1, width = 6.5, height = 4,
units = "in", dpi = 300)

write.xlsx(data, "data.relimpo.xlsx") setwd("C:/Owner/AJ
Thurston/Desktop")

domresm = melt(data=domres, id.vars = Model) help(melt)
colnames(domresm) = c("Predictor","Model", "Importance")

for (i in models) { assign(paste(names(i),"lm",sep = "."), i) }

names(models) models
